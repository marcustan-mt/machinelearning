{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6906734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marcu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Processing c:\\users\\marcu\\desktop\\ga tech\\ml\\ml-sp24\\mlrose\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.5.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from pandas->mlrose-hiive==2.2.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from pandas->mlrose-hiive==2.2.4) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from scikit-learn->mlrose-hiive==2.2.4) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->mlrose-hiive==2.2.4) (1.16.0)\n",
      "Building wheels for collected packages: mlrose-hiive\n",
      "  Building wheel for mlrose-hiive (setup.py): started\n",
      "  Building wheel for mlrose-hiive (setup.py): finished with status 'done'\n",
      "  Created wheel for mlrose-hiive: filename=mlrose_hiive-2.2.4-py3-none-any.whl size=103936 sha256=fba107a10f9bc16b4e9e382c608748184a7b5e2adb1a1d11b549fc0b84140e59\n",
      "  Stored in directory: C:\\Users\\marcu\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-lrv33so4\\wheels\\1b\\71\\20\\a26b3f48984937d91461af271cddc3ba8371491b048e63bbfa\n",
      "Successfully built mlrose-hiive\n",
      "Installing collected packages: mlrose-hiive\n",
      "  Attempting uninstall: mlrose-hiive\n",
      "    Found existing installation: mlrose-hiive 2.2.4\n",
      "    Uninstalling mlrose-hiive-2.2.4:\n",
      "      Successfully uninstalled mlrose-hiive-2.2.4\n",
      "Successfully installed mlrose-hiive-2.2.4\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "from platform import python_version\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,train_test_split,cross_val_score, KFold, StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, precision_recall_fscore_support, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# ! pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import backend as K\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras.optimizers import Adam, SGD\n",
    "! pip install \"C:\\Users\\marcu\\Desktop\\GA Tech\\ML\\ML-SP24\\mlrose\"\n",
    "import mlrose_hiive\n",
    "from mlrose_hiive.runners import SKMLPRunner\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01924fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ingestion():\n",
    "    # Ingesting Wine Quality Dataset\n",
    "    wine = pd.read_csv(r'C:\\Users\\marcu\\Desktop\\GA Tech\\ML\\ML-SP24\\Assignment 2\\winequality-white.csv')\n",
    "    column_names = wine.columns.tolist()\n",
    "    # Standardize the values in all columns\n",
    "    scaler = StandardScaler()\n",
    "    columns_stand = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "    wine[columns_stand] = scaler.fit_transform(wine[columns_stand])\n",
    "    \n",
    "    # Encoding quality wine \n",
    "    label_encoder = LabelEncoder()\n",
    "    wine['encoded_quality'] = label_encoder.fit_transform(wine['quality'])\n",
    "    wine = wine.drop(columns=['quality'])\n",
    "    wine = wine.rename(columns={'encoded_quality': 'quality'})\n",
    "\n",
    "\n",
    "    # Descriptive Stats for Wine\n",
    "    df_wine = wine.describe()\n",
    "    df_wine.to_csv('descriptive/descriptive_stats_wine.csv')\n",
    "\n",
    "    # Output boxplot for outlier distribution\n",
    "    column_names = wine.columns.tolist()\n",
    "    for i in column_names:\n",
    "        column_data = wine[i].values\n",
    "        # Create boxplot using Matplotlib\n",
    "        plt.clf()\n",
    "        plt.boxplot(column_data)\n",
    "        plt.title(f'Box and Whisker Plot for Wine Quality for {i}')\n",
    "        plt.savefig(f'image/wine_{i}.png')\n",
    "\n",
    "    # Plotting Target Variable for Apple Quality\n",
    "    plt.clf()\n",
    "#     plt.hist(wine['quality'], label=i)\n",
    "    plt.savefig('image/wine_target.png', bbox_inches='tight')\n",
    "    \n",
    "    # Ingesting Apple Quality\n",
    "    aq = pd.read_csv(r'C:\\Users\\marcu\\Desktop\\GA Tech\\ML\\ML-SP24\\Assignment 2\\apple_quality.csv')\n",
    "    # Descriptive Stats for Wine\n",
    "    df_aq = aq.describe()\n",
    "    df_aq.to_csv('descriptive/descriptive_stats_aq.csv')\n",
    "    \n",
    "    # Output boxplot for outlier distribution\n",
    "    column_names = aq.columns.tolist()\n",
    "    for i in column_names:\n",
    "        column_data = aq[i].values\n",
    "        # Create boxplot using Matplotlib\n",
    "        plt.clf()\n",
    "        plt.boxplot(column_data)\n",
    "        plt.title(f'Box and Whisker Plot for Apple Quality for {i}')\n",
    "        plt.savefig(f'image/aq_{i}.png')\n",
    "\n",
    "    # Plotting Target Variable for Apple Quality\n",
    "    plt.clf()\n",
    "#     plt.hist(aq['Quality'], label=i)\n",
    "    plt.savefig('image/apple_target.png', bbox_inches='tight')\n",
    "    \n",
    "    return(wine,aq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f6b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(wine, aq):\n",
    "    list_w = wine.columns.tolist()\n",
    "    list_w.remove('quality')\n",
    "    x_train_w, x_test_w, y_train_w, y_test_w = train_test_split(wine[list_w], wine['quality'], test_size=0.3, random_state=42)\n",
    "\n",
    "    list_a = aq.columns.tolist()\n",
    "    list_a.remove('Quality')\n",
    "    x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(aq[list_a], aq['Quality'], test_size=0.3, random_state=42)\n",
    "\n",
    "    return(x_train_w, x_test_w, y_train_w, y_test_w, x_train_a, x_test_a, y_train_a, y_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb9adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_kfold_ann(clf, num_folds, x_train, y_train, dataset = 'wine', epochs = 5):\n",
    "    # Create a StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=num_folds, shuffle=True,random_state = 42)\n",
    "    \n",
    "    # Lists to store training and validation scores for each fold\n",
    "    training_scores = []\n",
    "    validation_scores = []\n",
    "    \n",
    "    # Iterate over folds\n",
    "    for fold_num, (train_index, val_index) in enumerate(stratified_kfold.split(x_train, y_train), start=1):\n",
    "\n",
    "\n",
    "        # Extract training and validation sets for this fold\n",
    "        X_train_sub, X_val_sub = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "        y_train_sub, y_val_sub = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        # One hot encoding\n",
    "        encoder = OneHotEncoder(sparse=False)\n",
    "        y_train_hot = encoder.fit_transform(y_train_sub.values.reshape(-1, 1))\n",
    "        y_val_hot = encoder.transform(y_val_sub.values.reshape(-1, 1))\n",
    "        \n",
    "        \n",
    "        # Train the Decision Tree model\n",
    "        clf.fit(X_train_sub, y_train_hot)\n",
    "\n",
    "        if dataset == 'wine':\n",
    "            # Make predictions on the training set\n",
    "            predictions_train = clf.predict(X_train_sub)\n",
    "            y_train_pred = np.argmax(predictions_train, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_train_sub = np.argmax(y_train_hot, axis=1)\n",
    "            \n",
    "            # Make predictions on the validation set\n",
    "            predictions_val = clf.predict(X_val_sub)\n",
    "            y_val_pred = np.argmax(predictions_val, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_val_sub = np.argmax(y_val_hot, axis=1)\n",
    "\n",
    "        else:            \n",
    "            # Make predictions on the training set\n",
    "            predictions_train = clf.predict(X_train_sub)\n",
    "            y_train_pred = (predictions_train > 0.5).astype(int)\n",
    "            \n",
    "            # Make predictions on the validation set\n",
    "            predictions_val = clf.predict(X_val_sub)\n",
    "            y_val_pred = (predictions_val > 0.5).astype(int)\n",
    "\n",
    "        # Calculate recall scores for training set\n",
    "        _, recall_train, _, _ = precision_recall_fscore_support(y_train_sub, y_train_pred, average='micro')\n",
    "        training_scores.append(recall_train)\n",
    "\n",
    "        # Calculate recall scores for validation sets\n",
    "        _, recall_val, _, _ = precision_recall_fscore_support(y_val_sub, y_val_pred, average='micro')\n",
    "        validation_scores.append(recall_val)\n",
    "\n",
    "    # Print mean scores across all folds\n",
    "    mean_training_score = np.mean(training_scores)\n",
    "    mean_validation_score = np.mean(validation_scores)\n",
    "#     print(mean_validation_score, mean_training_score)\n",
    "    return(mean_validation_score, mean_training_score)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ec3799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data ingestion\n",
    "wine,aq = data_ingestion()\n",
    "x_train_w, x_test_w, y_train_w, y_test_w, x_train_a, x_test_a, y_train_a, y_test_a = train_test(wine,aq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53df0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_kfold_ann(clf, num_folds, x_train, y_train, dataset = 'wine', epochs = 5):\n",
    "    # Create a StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=num_folds, shuffle=True,random_state = 42)\n",
    "    \n",
    "    # Lists to store training and validation scores for each fold\n",
    "    training_scores = []\n",
    "    validation_scores = []\n",
    "    \n",
    "    # Iterate over folds\n",
    "    for fold_num, (train_index, val_index) in enumerate(stratified_kfold.split(x_train, y_train), start=1):\n",
    "\n",
    "\n",
    "        # Extract training and validation sets for this fold\n",
    "        X_train_sub, X_val_sub = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "        y_train_sub, y_val_sub = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        # One hot encoding\n",
    "        encoder = OneHotEncoder(sparse=False)\n",
    "        y_train_hot = encoder.fit_transform(y_train_sub.values.reshape(-1, 1))\n",
    "        y_val_hot = encoder.transform(y_val_sub.values.reshape(-1, 1))\n",
    "        \n",
    "        \n",
    "        # Train the Decision Tree model\n",
    "        clf.fit(X_train_sub, y_train_hot)\n",
    "\n",
    "        if dataset == 'wine':\n",
    "            # Make predictions on the training set\n",
    "            predictions_train = clf.predict(X_train_sub)\n",
    "            y_train_pred = np.argmax(predictions_train, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_train_sub = np.argmax(y_train_hot, axis=1)\n",
    "            \n",
    "            # Make predictions on the validation set\n",
    "            predictions_val = clf.predict(X_val_sub)\n",
    "            y_val_pred = np.argmax(predictions_val, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_val_sub = np.argmax(y_val_hot, axis=1)\n",
    "\n",
    "        else:            \n",
    "            # Make predictions on the training set\n",
    "            predictions_train = clf.predict(X_train_sub)\n",
    "            y_train_pred = np.argmax(predictions_train, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_train_sub = np.argmax(y_train_hot, axis=1)\n",
    "            \n",
    "            # Make predictions on the validation set\n",
    "            predictions_val = clf.predict(X_val_sub)\n",
    "            y_val_pred = np.argmax(predictions_val, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_val_sub = np.argmax(y_val_hot, axis=1)\n",
    "\n",
    "        # Calculate recall scores for training set\n",
    "        _, recall_train, _, _ = precision_recall_fscore_support(y_train_sub, y_train_pred, average='micro')\n",
    "        training_scores.append(recall_train)\n",
    "\n",
    "        # Calculate recall scores for validation sets\n",
    "        _, recall_val, _, _ = precision_recall_fscore_support(y_val_sub, y_val_pred, average='micro')\n",
    "        validation_scores.append(recall_val)\n",
    "\n",
    "    # Print mean scores across all folds\n",
    "    mean_training_score = np.mean(training_scores)\n",
    "    mean_validation_score = np.mean(validation_scores)\n",
    "#     print(mean_validation_score, mean_training_score)\n",
    "    return(mean_validation_score, mean_training_score)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e676f",
   "metadata": {},
   "source": [
    "# Optimal Hyperparameters for SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "713632eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.411543130874634\n",
      "schedule:  1000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.844494342803955\n",
      "schedule:  100000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  11.136213779449463\n",
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.523642301559448\n",
      "schedule:  1000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.814923286437988\n",
      "schedule:  100000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.83003544807434\n",
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  9.993237733840942\n",
      "schedule:  1000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.896575689315796\n",
      "schedule:  100000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.915379047393799\n",
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  10.223137855529785\n"
     ]
    }
   ],
   "source": [
    "schedule = [mlrose_hiive.GeomDecay(init_temp = 10000000000, decay=0.9, min_temp=0.1),\n",
    "            mlrose_hiive.GeomDecay(init_temp = 1000000, decay=0.8, min_temp=0.1),\n",
    "            mlrose_hiive.GeomDecay(init_temp = 100000000, decay=0.7, min_temp=0.1),\n",
    "            mlrose_hiive.GeomDecay(init_temp = 10000000000, decay=0.6, min_temp=0.1),\n",
    "            mlrose_hiive.ArithDecay(init_temp=1000000, decay=0.9, min_temp=0.1),\n",
    "            mlrose_hiive.ArithDecay(init_temp=100000000, decay=0.8, min_temp=0.1),\n",
    "            mlrose_hiive.ArithDecay(init_temp=10000000000, decay=0.7, min_temp=0.1),\n",
    "            mlrose_hiive.ExpDecay(init_temp=1000000, exp_const=0.9, min_temp=0.1),\n",
    "            mlrose_hiive.ExpDecay(init_temp=100000000, exp_const=0.8, min_temp=0.1),\n",
    "            mlrose_hiive.ExpDecay(init_temp=10000000000, exp_const=0.7, min_temp=0.1)]\n",
    "            \n",
    "for i in range(0,10):\n",
    "    start_time = time.time()\n",
    "    nn_model_base = mlrose_hiive.NeuralNetwork([64,64,64], activation = 'tanh', \n",
    "                     algorithm = 'simulated_annealing', max_iters = 1000, \n",
    "                     bias = True, is_classifier = True, learning_rate = 0.0001, \n",
    "                     early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                     random_state = 42, curve = True, restarts = 0, schedule = schedule[i])\n",
    "    val, train = strat_kfold_ann(nn_model_base, num_folds=2, x_train = x_train_a, y_train = y_train_a, dataset = 'apple', epochs = 5)\n",
    "    end_time = time.time()\n",
    "    wall_clock_time = end_time - start_time\n",
    "    print('schedule: ', schedule[i], 'validation recall: ', val , 'training recall: ', train,  'wall clock time: ', wall_clock_time)\n",
    "\n",
    "# Optimal Hyperparameter: tanh, LR: 0.0001, [64,64,64], init temp = 1000000, decay = 0.8, min_temp = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bca7711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  6.344626188278198\n",
      "schedule:  1000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  12.279746532440186\n",
      "schedule:  100000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  18.26729440689087\n",
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  24.37312078475952\n",
      "schedule:  1000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  31.598753690719604\n",
      "schedule:  100000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  36.76738142967224\n",
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  42.5236976146698\n",
      "schedule:  1000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  48.45054650306702\n",
      "schedule:  100000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  54.79163932800293\n",
      "schedule:  10000000000 validation recall:  0.4692857142857143 training recall:  0.4692857142857143 wall clock time:  61.37480568885803\n"
     ]
    }
   ],
   "source": [
    "ftcurves = []\n",
    "for i in range(0,10):\n",
    "    start_time = time.time()\n",
    "    nn_model_base = mlrose_hiive.NeuralNetwork([64,64,64], activation = 'tanh', \n",
    "                     algorithm = 'simulated_annealing', max_iters = 500 + 500*i, \n",
    "                     bias = True, is_classifier = True, learning_rate = 0.0001, \n",
    "                     early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                     random_state = 42, curve = True, restarts = 0, schedule = mlrose_hiive.GeomDecay(init_temp = 1000000, decay=0.8, min_temp=0.1))\n",
    "    val, train = strat_kfold_ann(nn_model_base, num_folds=2, x_train = x_train_a, y_train = y_train_a, dataset = 'apple', epochs = 5)\n",
    "    end_time = time.time()\n",
    "    ftcurves.append(nn_model_base.fitness_curve)\n",
    "    wall_clock_time = end_time - start_time\n",
    "    print('schedule: ', schedule[i], 'validation recall: ', val , 'training recall: ', train,  'wall clock time: ', wall_clock_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schedule:  10000000000 validation recall:  0.6467857142857143 training recall:  0.6375 wall clock time:  5396.553777694702\n",
      "schedule:  1000000 validation recall:  0.6467857142857143 training recall:  0.6375 wall clock time:  3080.9285576343536\n",
      "schedule:  100000000 validation recall:  0.6467857142857143 training recall:  0.6375 wall clock time:  7465.860976219177\n",
      "schedule:  10000000000 validation recall:  0.6467857142857143 training recall:  0.6375 wall clock time:  1471.5561723709106\n",
      "schedule:  1000000 validation recall:  0.6467857142857143 training recall:  0.6375 wall clock time:  1465.5822439193726\n"
     ]
    }
   ],
   "source": [
    "ftcurve = []\n",
    "for i in range(0,10):\n",
    "    start_time = time.time()\n",
    "    nn_model_base = mlrose_hiive.NeuralNetwork([64,64,64], activation = 'tanh', \n",
    "                     algorithm = 'genetic_alg', max_iters = 500 + 500*i, \n",
    "                     bias = True, is_classifier = True, learning_rate = 0.0001, \n",
    "                     early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                     random_state = 42, curve = True, restarts = 0, schedule = 0, pop_size = 500, mutation_prob = 0.5)\n",
    "    val, train = strat_kfold_ann(nn_model_base, num_folds=2, x_train = x_train_a, y_train = y_train_a, dataset = 'apple', epochs = 5)\n",
    "    end_time = time.time()\n",
    "    ftcurve.append(nn_model_base.fitness_curve)\n",
    "    wall_clock_time = end_time - start_time\n",
    "    print('schedule: ', schedule[i], 'validation recall: ', val , 'training recall: ', train,  'wall clock time: ', wall_clock_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
