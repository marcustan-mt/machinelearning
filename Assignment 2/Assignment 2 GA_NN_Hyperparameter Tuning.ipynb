{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b669f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marcu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Processing c:\\users\\marcu\\desktop\\ga tech\\ml\\ml-sp24\\mlrose\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.5.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from mlrose-hiive==2.2.4) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from pandas->mlrose-hiive==2.2.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from pandas->mlrose-hiive==2.2.4) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from scikit-learn->mlrose-hiive==2.2.4) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marcu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->mlrose-hiive==2.2.4) (1.16.0)\n",
      "Building wheels for collected packages: mlrose-hiive\n",
      "  Building wheel for mlrose-hiive (setup.py): started\n",
      "  Building wheel for mlrose-hiive (setup.py): finished with status 'done'\n",
      "  Created wheel for mlrose-hiive: filename=mlrose_hiive-2.2.4-py3-none-any.whl size=103936 sha256=44c47c473960becf4d15471a7d801c0dce22928de48b35e2f703c8a8a3c6c5f4\n",
      "  Stored in directory: C:\\Users\\marcu\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-6zd5c2zk\\wheels\\1b\\71\\20\\a26b3f48984937d91461af271cddc3ba8371491b048e63bbfa\n",
      "Successfully built mlrose-hiive\n",
      "Installing collected packages: mlrose-hiive\n",
      "  Attempting uninstall: mlrose-hiive\n",
      "    Found existing installation: mlrose-hiive 2.2.4\n",
      "    Uninstalling mlrose-hiive-2.2.4:\n",
      "      Successfully uninstalled mlrose-hiive-2.2.4\n",
      "Successfully installed mlrose-hiive-2.2.4\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "from platform import python_version\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,train_test_split,cross_val_score, KFold, StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, precision_recall_fscore_support, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# ! pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import backend as K\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras.optimizers import Adam, SGD\n",
    "! pip install \"C:\\Users\\marcu\\Desktop\\GA Tech\\ML\\ML-SP24\\mlrose\"\n",
    "import mlrose_hiive\n",
    "from mlrose_hiive.runners import SKMLPRunner\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c57961d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ingestion():\n",
    "    # Ingesting Wine Quality Dataset\n",
    "    wine = pd.read_csv(r'C:\\Users\\marcu\\Desktop\\GA Tech\\ML\\ML-SP24\\Assignment 2\\winequality-white.csv')\n",
    "    column_names = wine.columns.tolist()\n",
    "    # Standardize the values in all columns\n",
    "    scaler = StandardScaler()\n",
    "    columns_stand = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "    wine[columns_stand] = scaler.fit_transform(wine[columns_stand])\n",
    "    \n",
    "    # Encoding quality wine \n",
    "    label_encoder = LabelEncoder()\n",
    "    wine['encoded_quality'] = label_encoder.fit_transform(wine['quality'])\n",
    "    wine = wine.drop(columns=['quality'])\n",
    "    wine = wine.rename(columns={'encoded_quality': 'quality'})\n",
    "\n",
    "\n",
    "    # Descriptive Stats for Wine\n",
    "    df_wine = wine.describe()\n",
    "    df_wine.to_csv('descriptive/descriptive_stats_wine.csv')\n",
    "\n",
    "    # Output boxplot for outlier distribution\n",
    "    column_names = wine.columns.tolist()\n",
    "    for i in column_names:\n",
    "        column_data = wine[i].values\n",
    "        # Create boxplot using Matplotlib\n",
    "        plt.clf()\n",
    "        plt.boxplot(column_data)\n",
    "        plt.title(f'Box and Whisker Plot for Wine Quality for {i}')\n",
    "        plt.savefig(f'image/wine_{i}.png')\n",
    "\n",
    "    # Plotting Target Variable for Apple Quality\n",
    "    plt.clf()\n",
    "#     plt.hist(wine['quality'], label=i)\n",
    "    plt.savefig('image/wine_target.png', bbox_inches='tight')\n",
    "    \n",
    "    # Ingesting Apple Quality\n",
    "    aq = pd.read_csv(r'C:\\Users\\marcu\\Desktop\\GA Tech\\ML\\ML-SP24\\Assignment 2\\apple_quality.csv')\n",
    "    # Descriptive Stats for Wine\n",
    "    df_aq = aq.describe()\n",
    "    df_aq.to_csv('descriptive/descriptive_stats_aq.csv')\n",
    "    \n",
    "    # Output boxplot for outlier distribution\n",
    "    column_names = aq.columns.tolist()\n",
    "    for i in column_names:\n",
    "        column_data = aq[i].values\n",
    "        # Create boxplot using Matplotlib\n",
    "        plt.clf()\n",
    "        plt.boxplot(column_data)\n",
    "        plt.title(f'Box and Whisker Plot for Apple Quality for {i}')\n",
    "        plt.savefig(f'image/aq_{i}.png')\n",
    "\n",
    "    # Plotting Target Variable for Apple Quality\n",
    "    plt.clf()\n",
    "#     plt.hist(aq['Quality'], label=i)\n",
    "    plt.savefig('image/apple_target.png', bbox_inches='tight')\n",
    "    \n",
    "    return(wine,aq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d19b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(wine, aq):\n",
    "    list_w = wine.columns.tolist()\n",
    "    list_w.remove('quality')\n",
    "    x_train_w, x_test_w, y_train_w, y_test_w = train_test_split(wine[list_w], wine['quality'], test_size=0.3, random_state=42)\n",
    "\n",
    "    list_a = aq.columns.tolist()\n",
    "    list_a.remove('Quality')\n",
    "    x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(aq[list_a], aq['Quality'], test_size=0.3, random_state=42)\n",
    "\n",
    "    return(x_train_w, x_test_w, y_train_w, y_test_w, x_train_a, x_test_a, y_train_a, y_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c2de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_kfold_ann(clf, num_folds, x_train, y_train, dataset = 'wine', epochs = 5):\n",
    "    # Create a StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=num_folds, shuffle=True,random_state = 42)\n",
    "    \n",
    "    # Lists to store training and validation scores for each fold\n",
    "    training_scores = []\n",
    "    validation_scores = []\n",
    "    \n",
    "    # Iterate over folds\n",
    "    for fold_num, (train_index, val_index) in enumerate(stratified_kfold.split(x_train, y_train), start=1):\n",
    "\n",
    "\n",
    "        # Extract training and validation sets for this fold\n",
    "        X_train_sub, X_val_sub = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "        y_train_sub, y_val_sub = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        # One hot encoding\n",
    "        encoder = OneHotEncoder(sparse=False)\n",
    "        y_train_hot = encoder.fit_transform(y_train_sub.values.reshape(-1, 1))\n",
    "        y_val_hot = encoder.transform(y_val_sub.values.reshape(-1, 1))\n",
    "        \n",
    "        \n",
    "        # Train the Decision Tree model\n",
    "        clf.fit(X_train_sub, y_train_hot)\n",
    "\n",
    "        if dataset == 'wine':\n",
    "            # Make predictions on the training set\n",
    "            predictions_train = clf.predict(X_train_sub)\n",
    "            y_train_pred = np.argmax(predictions_train, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_train_sub = np.argmax(y_train_hot, axis=1)\n",
    "            \n",
    "            # Make predictions on the validation set\n",
    "            predictions_val = clf.predict(X_val_sub)\n",
    "            y_val_pred = np.argmax(predictions_val, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_val_sub = np.argmax(y_val_hot, axis=1)\n",
    "\n",
    "        else:            \n",
    "            # Make predictions on the training set\n",
    "            predictions_train = clf.predict(X_train_sub)\n",
    "            y_train_pred = np.argmax(predictions_train, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_train_sub = np.argmax(y_train_hot, axis=1)\n",
    "            \n",
    "            # Make predictions on the validation set\n",
    "            predictions_val = clf.predict(X_val_sub)\n",
    "            y_val_pred = np.argmax(predictions_val, axis=1)\n",
    "            \n",
    "            # Converting y_train_sub into the quality category \n",
    "            y_val_sub = np.argmax(y_val_hot, axis=1)\n",
    "\n",
    "        # Calculate recall scores for training set\n",
    "        _, recall_train, _, _ = precision_recall_fscore_support(y_train_sub, y_train_pred, average='micro')\n",
    "        training_scores.append(recall_train)\n",
    "\n",
    "        # Calculate recall scores for validation sets\n",
    "        _, recall_val, _, _ = precision_recall_fscore_support(y_val_sub, y_val_pred, average='micro')\n",
    "        validation_scores.append(recall_val)\n",
    "\n",
    "    # Print mean scores across all folds\n",
    "    mean_training_score = np.mean(training_scores)\n",
    "    mean_validation_score = np.mean(validation_scores)\n",
    "#     print(mean_validation_score, mean_training_score)\n",
    "    return(mean_validation_score, mean_training_score)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94d1f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data ingestion\n",
    "wine,aq = data_ingestion()\n",
    "x_train_w, x_test_w, y_train_w, y_test_w, x_train_a, x_test_a, y_train_a, y_test_a = train_test(wine,aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22053d2d",
   "metadata": {},
   "source": [
    "# Optimal Hyperparameters for GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68d26609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop_size:  700 mutation_prob:  0.7 validation recall:  0.6142857142857143 training recall:  0.6214285714285714 wall clock time:  1487.3166959285736\n",
      "pop_size:  700 mutation_prob:  0.5 validation recall:  0.5985714285714285 training recall:  0.6028571428571429 wall clock time:  7169.323969841003\n",
      "pop_size:  700 mutation_prob:  0.1 validation recall:  0.5892857142857143 training recall:  0.6239285714285714 wall clock time:  5033.533531188965\n",
      "pop_size:  700 mutation_prob:  0.3 validation recall:  0.5932142857142857 training recall:  0.5903571428571428 wall clock time:  10420.80622124672\n",
      "pop_size:  500 mutation_prob:  0.7 validation recall:  0.5925 training recall:  0.6253571428571428 wall clock time:  7773.548013687134\n",
      "pop_size:  500 mutation_prob:  0.5 validation recall:  0.6467857142857143 training recall:  0.6375 wall clock time:  10689.922334909439\n",
      "pop_size:  500 mutation_prob:  0.1 validation recall:  0.5742857142857143 training recall:  0.6042857142857143 wall clock time:  14314.443961143494\n",
      "pop_size:  500 mutation_prob:  0.3 validation recall:  0.5974999999999999 training recall:  0.6232142857142857 wall clock time:  2952.138088464737\n",
      "pop_size:  300 mutation_prob:  0.7 validation recall:  0.6225 training recall:  0.6407142857142858 wall clock time:  1300.8368437290192\n",
      "pop_size:  300 mutation_prob:  0.5 validation recall:  0.6221428571428571 training recall:  0.6460714285714286 wall clock time:  1012.9756634235382\n",
      "pop_size:  300 mutation_prob:  0.1 validation recall:  0.6303571428571428 training recall:  0.6525000000000001 wall clock time:  604.8044292926788\n",
      "pop_size:  300 mutation_prob:  0.3 validation recall:  0.5889285714285715 training recall:  0.5917857142857142 wall clock time:  4439.944794893265\n",
      "pop_size:  100 mutation_prob:  0.7 validation recall:  0.6028571428571429 training recall:  0.6085714285714285 wall clock time:  280.79900908470154\n",
      "pop_size:  100 mutation_prob:  0.5 validation recall:  0.6314285714285715 training recall:  0.6142857142857143 wall clock time:  1888.6777610778809\n",
      "pop_size:  100 mutation_prob:  0.1 validation recall:  0.6167857142857143 training recall:  0.6221428571428571 wall clock time:  172.76332664489746\n",
      "pop_size:  100 mutation_prob:  0.3 validation recall:  0.6039285714285714 training recall:  0.6285714285714286 wall clock time:  185.912207365036\n"
     ]
    }
   ],
   "source": [
    "pop_size = [700,500,300,100]\n",
    "mutation_prob = [0.7,0.5,0.1,0.3]\n",
    "\n",
    "for i in range(0,4):\n",
    "    for x in range(0,4):\n",
    "        start_time = time.time()\n",
    "        nn_model_base = mlrose_hiive.NeuralNetwork([64,64,64], activation = 'tanh', \n",
    "                         algorithm = 'genetic_alg', max_iters = 1000, \n",
    "                         bias = True, is_classifier = True, learning_rate = 0.0001, \n",
    "                         early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                         random_state = 42, curve = True, pop_size = pop_size[i], mutation_prob = mutation_prob[x])\n",
    "        val, train = strat_kfold_ann(nn_model_base, num_folds=2, x_train = x_train_a, y_train = y_train_a, dataset = 'apple', epochs = 5)\n",
    "        end_time = time.time()\n",
    "        wall_clock_time = end_time - start_time\n",
    "        print('pop_size: ', pop_size[i], 'mutation_prob: ', mutation_prob[x] , 'validation recall: ', val , 'training recall: ', train,  'wall clock time: ', wall_clock_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce80717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best State: [0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0\n",
      " 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1\n",
      " 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1]\n",
      "Best Fitness: 79.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the fitness function for the Flip Flop problem\n",
    "fitness_flip_flop = mlrose_hiive.FlipFlop()\n",
    "\n",
    "# Define the optimization problem\n",
    "problem = mlrose_hiive.DiscreteOpt(length=100, fitness_fn=fitness_flip_flop, maximize=True, max_val=2)\n",
    "\n",
    "# Define the initial state\n",
    "init_state = np.random.randint(2, size=100)\n",
    "\n",
    "# Define the decay schedule for simulated annealing\n",
    "schedule = mlrose_hiive.GeomDecay(init_temp = 1e10, decay = 0.35)\n",
    "\n",
    "# Run simulated annealing to optimize the problem\n",
    "best_state, best_fitness, a = mlrose_hiive.simulated_annealing(problem, schedule=schedule, max_attempts=10, max_iters=1000, init_state=init_state, random_state=42)\n",
    "\n",
    "print(\"Best State:\", best_state)\n",
    "print(\"Best Fitness:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b98f8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1\n",
      " 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1] 74.0\n",
      "[0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0\n",
      " 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1\n",
      " 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1] 79.0\n",
      "[0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1] 91.0\n",
      "[0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1\n",
      " 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 0] 72.0\n"
     ]
    }
   ],
   "source": [
    "# Run simulated annealing to optimize the problem\n",
    "best_state, best_fitness, fitness_curve = mlrose_hiive.random_hill_climb(problem, \n",
    "                                                                          max_attempts = 100,\n",
    "                                                                          max_iters = 1000,\n",
    "                                                                          restarts = 0,\n",
    "                                                                          init_state = init_state,\n",
    "                                                                          curve = True,\n",
    "                                                                          random_state = 42)\n",
    "print(best_state, best_fitness)\n",
    "best_state, best_fitness, a = mlrose_hiive.simulated_annealing(problem, schedule=schedule, max_attempts=10, max_iters=1000, curve= True, init_state=init_state, random_state=42)\n",
    "\n",
    "print(best_state, best_fitness)\n",
    "\n",
    "best_state, best_fitness, fitness_curve = mlrose_hiive.genetic_alg(problem, \n",
    "\n",
    "                                                                   pop_size = 100,\n",
    "                                                                   mutation_prob = 0.5, \n",
    "                                                                   max_attempts = 100,\n",
    "                                                                   max_iters = 1000,\n",
    "                                                                   curve = True,\n",
    "                                                                   random_state = 42)\n",
    "print(best_state, best_fitness)\n",
    "\n",
    "best_state, best_fitness, a = mlrose_hiive.mimic(problem, \n",
    "                                                 pop_size = 100, \n",
    "                                                 keep_pct = 0.9,\n",
    "                                                 max_attempts = 100,\n",
    "                                                 max_iters = 1000,\n",
    "                                                 curve = True,\n",
    "                                                 random_state = 42)\n",
    "print(best_state, best_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59a061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = mlrose_hiive.MIMICRunner(problem=problem,\n",
    "                                experiment_name=f'aa_mimic.csv',\n",
    "                                #                           output_directory='.',\n",
    "                                seed=42,\n",
    "                                iteration_list=[100,200,300,400,500],\n",
    "                                max_attempts=100,\n",
    "                                keep_percent_list=[0.1,0.2,0.3,0.4,0.5],\n",
    "                                population_sizes = [100,200,300,400,500])\n",
    "\n",
    "df_run_stats, df_run_curves = runner.run()\n",
    "df_run_stats.to_csv('aa_mimic.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
